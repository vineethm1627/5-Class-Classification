{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dphi-official/Deep_Learning_Bootcamp/blob/master/Assignment_2/Getting_Started_Notebook_Intermediate_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "01quEXe2_bkz"
   },
   "source": [
    "**Please follow the below instructions to load the dataset in Notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SD3WuCgn_rTe"
   },
   "source": [
    "## Download Data\n",
    "We are given google drive link in the ‘Data’ section of problem page which has all the required train images (to build the model) and test data images for which one need to predict the labels (animal specie) of these images and submit the predictions on the DPhi platform.\n",
    "\n",
    "\n",
    "\n",
    "We can use GoogleDriveDownloader from google_drive_downloader library in Python to download the shared files from the Google drive link: https://drive.google.com/file/d/176E-pLhoxTgWsJ3MeoJQV_GXczIA6g8D/view?usp=sharing\n",
    "\n",
    "The file id in the above link is: 176E-pLhoxTgWsJ3MeoJQV_GXczIA6g8D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgxihnh0LCHQ"
   },
   "source": [
    "**Now we are all set to start the data science work!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJnmEJt9EY-2"
   },
   "source": [
    "## Loading Libraries\n",
    "Let's import the required libraries. Not importing all the libraries in one go instead we will be importing whenever we require one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xb2W2sgLBim4"
   },
   "outputs": [],
   "source": [
    "# import the basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fv0LmgNbEwR0"
   },
   "source": [
    "## Loading the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnUBZ_ZOEvOa"
   },
   "outputs": [],
   "source": [
    "categories = {\"elefante_train\": \"elefante\", \"farfalla_train\": \"farfalla\", \"mucca_train\": \"mucca\", \"pecora_train\": \"pecora\", \"scoiattolo_train\": \"scoiattolo\"}\n",
    "data=[]\n",
    "animals=[\"elefante\", \"farfalla\", \"mucca\",  \"pecora\", \"scoiattolo\"]\n",
    "img_size=100      # Here we are taking image size as 100, but it's on you. You can take 50 or 40 or 32 and so on\n",
    "def create_data():\n",
    "        for category,translate in categories.items():\n",
    "            path=\"animal_dataset_intermediate/train/\"+category\n",
    "            target=animals.index(translate)     # converting the categorical values to numbers - 0, 1, 2, 3, 4 denoting the animals in animals list\n",
    "            \n",
    "            for img in os.listdir(path):         # os.listdir gets you all the list of name of files located in the given path\n",
    "                try:\n",
    "                    img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)    # converts the image to pixels and gray scales the images\n",
    "                    new_img_array=cv2.resize(img_array,(img_size,img_size))              # resizing the images\n",
    "                    data.append([new_img_array,target])                                  # appending the list of image pixels and respective target value (i.e. animal type) in data\n",
    "                except Exception as e:\n",
    "                    pass                                      # try and except is exception handling case in python, saves you from getting errors\n",
    "                \n",
    "            \n",
    "create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtJqd-PNgRpu",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data   # data contains all the images pixel values and their respective labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8196\n"
     ]
    }
   ],
   "source": [
    "# we can observe that there are 8196 number of images\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One training example :  [array([[122, 124, 125, ..., 123, 123, 121],\n",
      "       [129, 130, 135, ..., 123, 124, 123],\n",
      "       [125, 124, 137, ..., 125, 124, 124],\n",
      "       ...,\n",
      "       [123, 143, 145, ...,  88,  89,  72],\n",
      "       [118, 128, 142, ...,  93,  82, 100],\n",
      "       [127, 127, 119, ...,  87,  70, 108]], dtype=uint8), 0]\n",
      "----------------------------------------------------\n",
      "image array :  [[122 124 125 ... 123 123 121]\n",
      " [129 130 135 ... 123 124 123]\n",
      " [125 124 137 ... 125 124 124]\n",
      " ...\n",
      " [123 143 145 ...  88  89  72]\n",
      " [118 128 142 ...  93  82 100]\n",
      " [127 127 119 ...  87  70 108]]\n",
      "----------------------------------------------------\n",
      "image array shape :  (100, 100)\n",
      "----------------------------------------------------\n",
      "category label :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"One training example : \", data[0])\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"image array : \", data[0][0])\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"image array shape : \", data[0][0].shape)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"category label : \", data[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AgcCiao3ciQ3"
   },
   "source": [
    "## Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for i in range(len(data)):\n",
    "    X.append(data[i][0])\n",
    "    y.append(data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One training example's X [input image] :  [[122 124 125 ... 123 123 121]\n",
      " [129 130 135 ... 123 124 123]\n",
      " [125 124 137 ... 125 124 124]\n",
      " ...\n",
      " [123 143 145 ...  88  89  72]\n",
      " [118 128 142 ...  93  82 100]\n",
      " [127 127 119 ...  87  70 108]]\n",
      "----------------------------------------------------\n",
      "One training example's shape :  (100, 100)\n",
      "----------------------------------------------------\n",
      "One training example's y [label/category] :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"One training example's X [input image] : \", X[0])\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"One training example's shape : \", X[0].shape)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"One training example's y [label/category] : \", y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8196, 100, 100)\n",
      "(8196, 5)\n"
     ]
    }
   ],
   "source": [
    "# no. of training examples / batch size, height, width\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ftcG0gxacKV-"
   },
   "outputs": [],
   "source": [
    "# Can split data using train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape :  (5737, 100, 100)\n",
      "y train shape :  (5737, 5)\n",
      "X test shape :  (2459, 100, 100)\n",
      "y test shape :  (2459, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train shape : \", X_train.shape)\n",
    "print(\"y train shape : \", y_train.shape)\n",
    "print(\"X test shape : \", X_test.shape)\n",
    "print(\"y test shape : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKuPUvVVVpee"
   },
   "source": [
    "## Building Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal classes :  ['elefante', 'farfalla', 'mucca', 'pecora', 'scoiattolo']\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(animals)\n",
    "print(\"animal classes : \", animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KycYYRpFVcoF"
   },
   "outputs": [],
   "source": [
    "# building a MLP\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Flatten(input_shape = (100, 100)))\n",
    "model1.add(Dense(512, activation = 'relu', name = 'layer1'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(256, activation = 'relu', name = 'layer2'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(num_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 512)               5120512   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 5,253,125\n",
      "Trainable params: 5,253,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary of the model\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XC-89PXPWnKs"
   },
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "optimizer = Adam(learning_rate = 0.001)\n",
    "model1.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXlgaWFccFzm"
   },
   "outputs": [],
   "source": [
    "# tensorboard visualization\n",
    "path = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=path, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 1/90 [..............................] - ETA: 0s - loss: 265.4891 - accuracy: 0.1094WARNING:tensorflow:From C:\\Users\\vinee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/90 [..............................] - ETA: 23s - loss: 1727.3276 - accuracy: 0.2109WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0252s vs `on_train_batch_end` time: 0.5085s). Check your callbacks.\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 324.3684 - accuracy: 0.2144\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 3s 34ms/step - loss: 1.6515 - accuracy: 0.2074\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 1.6077 - accuracy: 0.2210\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 1.5970 - accuracy: 0.2278\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 3s 34ms/step - loss: 1.6018 - accuracy: 0.2280\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 3s 33ms/step - loss: 1.6057 - accuracy: 0.2278 0s - loss: 1.6058 - accuracy: 0.\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 3s 33ms/step - loss: 1.6041 - accuracy: 0.2280\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 3s 33ms/step - loss: 1.6005 - accuracy: 0.2282\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 3s 33ms/step - loss: 1.5985 - accuracy: 0.2280\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 3s 34ms/step - loss: 1.6031 - accuracy: 0.2278\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 3s 34ms/step - loss: 1.5987 - accuracy: 0.2283\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 3s 34ms/step - loss: 1.6038 - accuracy: 0.2278\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 1.5979 - accuracy: 0.2280\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 1.5973 - accuracy: 0.2285 0s - loss: 1.5970 - accura\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 3s 34ms/step - loss: 1.5981 - accuracy: 0.2276 0s - loss: 1.5981 - accuracy: 0.22\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 1.5973 - accuracy: 0.2283\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 3s 33ms/step - loss: 1.6037 - accuracy: 0.2280\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 1.6002 - accuracy: 0.2285\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 3s 33ms/step - loss: 1.5992 - accuracy: 0.2283\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 1.6017 - accuracy: 0.2285 0s - loss: 1.6013 - accuracy: 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x187e56e24c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model on training data\n",
    "model1.fit(X_train, y_train, epochs = 20, batch_size = 64, verbose = 1, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13616), started 4:26:23 ago. (Use '!kill 13616' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-29a472d4a3f3a3a4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-29a472d4a3f3a3a4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5hxDG16dixs"
   },
   "source": [
    "## Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEz8zyzadl0b"
   },
   "outputs": [],
   "source": [
    "# building a CNN model.\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(filters = 32, kernel_size = (5, 5), activation = 'relu', input_shape = (100, 100, 1)))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256, activation = 'relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(5, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUd93mhpdmug"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 96, 96, 32)        832       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 3,373,445\n",
      "Trainable params: 3,372,485\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary of the CNN model\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vivxhUK8dmfq"
   },
   "outputs": [],
   "source": [
    "# compiling the CNN model\n",
    "model2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard visualization\n",
    "path = \"logs/fit2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback_1 = tf.keras.callbacks.TensorBoard(log_dir=path, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5737, 100, 100)\n",
      "(5737, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(-1, 100, 100, 1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "90/90 [==============================] - 74s 826ms/step - loss: 1.3780 - accuracy: 0.4851\n",
      "Epoch 2/15\n",
      "90/90 [==============================] - 73s 815ms/step - loss: 0.9449 - accuracy: 0.6408\n",
      "Epoch 3/15\n",
      "90/90 [==============================] - 74s 818ms/step - loss: 0.7670 - accuracy: 0.7072\n",
      "Epoch 4/15\n",
      "90/90 [==============================] - 73s 813ms/step - loss: 0.6556 - accuracy: 0.7534\n",
      "Epoch 5/15\n",
      "90/90 [==============================] - 75s 833ms/step - loss: 0.5315 - accuracy: 0.8023\n",
      "Epoch 6/15\n",
      "90/90 [==============================] - 75s 830ms/step - loss: 0.4246 - accuracy: 0.8524\n",
      "Epoch 7/15\n",
      "90/90 [==============================] - 74s 817ms/step - loss: 0.3220 - accuracy: 0.8830\n",
      "Epoch 8/15\n",
      "90/90 [==============================] - 79s 873ms/step - loss: 0.2562 - accuracy: 0.9125\n",
      "Epoch 9/15\n",
      "90/90 [==============================] - 116s 1s/step - loss: 0.1929 - accuracy: 0.9338\n",
      "Epoch 10/15\n",
      "90/90 [==============================] - 116s 1s/step - loss: 0.1500 - accuracy: 0.9542\n",
      "Epoch 11/15\n",
      "90/90 [==============================] - 115s 1s/step - loss: 0.1157 - accuracy: 0.9636\n",
      "Epoch 12/15\n",
      "90/90 [==============================] - 117s 1s/step - loss: 0.0820 - accuracy: 0.9775\n",
      "Epoch 13/15\n",
      "90/90 [==============================] - 116s 1s/step - loss: 0.0836 - accuracy: 0.9747\n",
      "Epoch 14/15\n",
      "90/90 [==============================] - 116s 1s/step - loss: 0.0714 - accuracy: 0.9805\n",
      "Epoch 15/15\n",
      "90/90 [==============================] - 117s 1s/step - loss: 0.0670 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x187e70aa130>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model on training data\n",
    "model2.fit(X_train, y_train, epochs = 15, batch_size = 64, verbose = 1, callbacks=[tensorboard_callback_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15648), started 3:49:03 ago. (Use '!kill 15648' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7d37ad965ea48b54\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7d37ad965ea48b54\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save the CNN model.\n",
    "\n",
    "model2.save('CNN_model_01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets load the saved model.\n",
    "\n",
    "model = load_model('CNN_model_01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 96, 96, 32)        832       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 3,373,445\n",
      "Trainable params: 3,372,485\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# printing the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSh2YMO9c80X"
   },
   "source": [
    "# Loading the Test Data\n",
    "We can load the test data similar to train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iseum_zjc53c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e030b20928e90021d85a5854ee454296eb70e3c818b413...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e030b20929e90021d85a5854ee454296eb70e3c818b413...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e030b2092be90021d85a5854ee454296eb70e3c818b413...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e030b2092ce90021d85a5854ee454296eb70e3c818b413...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e030b2092de90021d85a5854ee454296eb70e3c818b413...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  target\n",
       "0  e030b20928e90021d85a5854ee454296eb70e3c818b413...     NaN\n",
       "1  e030b20929e90021d85a5854ee454296eb70e3c818b413...     NaN\n",
       "2  e030b2092be90021d85a5854ee454296eb70e3c818b413...     NaN\n",
       "3  e030b2092ce90021d85a5854ee454296eb70e3c818b413...     NaN\n",
       "4  e030b2092de90021d85a5854ee454296eb70e3c818b413...     NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the csv file given 'Testing_set_animals.csv'\n",
    "test_image_ids = pd.read_csv(\"animal_dataset_intermediate/Testing_set_animals.csv\")\n",
    "test_image_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bkc8_Ry_dUo8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'animal_dataset_intermediate/test/e030b20928e90021d85a5854ee454296eb70e3c818b413449df6c87ca3ed_640.jpg'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get image paths\n",
    "image_paths = ['animal_dataset_intermediate/test/' + fname for fname in test_image_ids['filename']]\n",
    "image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXmLVJ7peu2I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e030b20928e90021d85a5854ee454296eb70e3c818b413...</td>\n",
       "      <td>animal_dataset_intermediate/test/e030b20928e90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e030b20929e90021d85a5854ee454296eb70e3c818b413...</td>\n",
       "      <td>animal_dataset_intermediate/test/e030b20929e90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e030b2092be90021d85a5854ee454296eb70e3c818b413...</td>\n",
       "      <td>animal_dataset_intermediate/test/e030b2092be90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e030b2092ce90021d85a5854ee454296eb70e3c818b413...</td>\n",
       "      <td>animal_dataset_intermediate/test/e030b2092ce90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e030b2092de90021d85a5854ee454296eb70e3c818b413...</td>\n",
       "      <td>animal_dataset_intermediate/test/e030b2092de90...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  e030b20928e90021d85a5854ee454296eb70e3c818b413...   \n",
       "1  e030b20929e90021d85a5854ee454296eb70e3c818b413...   \n",
       "2  e030b2092be90021d85a5854ee454296eb70e3c818b413...   \n",
       "3  e030b2092ce90021d85a5854ee454296eb70e3c818b413...   \n",
       "4  e030b2092de90021d85a5854ee454296eb70e3c818b413...   \n",
       "\n",
       "                                            filepath  \n",
       "0  animal_dataset_intermediate/test/e030b20928e90...  \n",
       "1  animal_dataset_intermediate/test/e030b20929e90...  \n",
       "2  animal_dataset_intermediate/test/e030b2092be90...  \n",
       "3  animal_dataset_intermediate/test/e030b2092ce90...  \n",
       "4  animal_dataset_intermediate/test/e030b2092de90...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe of image ids and filepaths\n",
    "test_data = pd.DataFrame({'filename': test_image_ids['filename'], 'filepath': image_paths })\n",
    "print(test_data.shape)\n",
    "test_data.head()\n",
    "# this is completely optional to see if all the data images are in an order. You can skip this if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal_dataset_intermediate/test/e030b20929e90021d85a5854ee454296eb70e3c818b413449df6c87ca3ed_640.jpg\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(test_data['filepath'][1])\n",
    "print(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPf2E4dZfOk6"
   },
   "outputs": [],
   "source": [
    "# Load image pixels using cv2\n",
    "image_pixels = []\n",
    "for i in range(test_data.shape[0]):\n",
    "    img_array = cv2.imread(test_data['filepath'][i], cv2.IMREAD_GRAYSCALE)\n",
    "    image_pixels.append(cv2.resize(img_array, (img_size, img_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pixels = np.array(image_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 100, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# lets bring it to the shape our model requires\n",
    "\n",
    "image_pixels = image_pixels.reshape(-1, 100, 100, 1)\n",
    "print(image_pixels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WLINT8JQb9Yz"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtQFzeFogwI_"
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "prediction = model.predict(image_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.8793025e-06 1.1330253e-02 1.7393626e-04 9.8835117e-01 1.3483877e-04]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(prediction[0])\n",
    "print(np.argmax(prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.argmax(prediction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 1, 3, 3, 0, 3, 4, 4, 3, 0, 0, 1, 4, 1, 4, 0, 4, 3],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(prediction[0])\n",
    "prediction[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCgiIiG9kG6S"
   },
   "source": [
    "**Note: Follow the submission guidelines given in ‘[How To Submit](https://discuss.dphi.tech/t/how-to-submit-predictions/548)’ Section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tI9CATQwkVJd"
   },
   "source": [
    "# **How to save prediciton results locally via jupyter notebook?**\n",
    "If you are working on Jupyter notebook, execute below block of codes. A file named ‘submission.csv’ will be created in your current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avhrRAeOkOOu"
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'filename': test_data['filename'], 'animal_type': prediction})  # prediction is nothing but the final predictions of your model on input features of your new unseen test data\n",
    "res.to_csv(\"submission_01.csv\", index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>animal_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>OIP-5ual0F5ZPZRdkGcj8uSH0AHaFj.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>OIP-5VwIBS0B8SxZbUiAHBJg7gHaE8.jpeg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>OIP-5WG0rHWAZYtu0utoZfuaAgHaFj.jpeg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>OIP-5ZwfeYunG6CT2wEI7OjybQHaEo.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>OIP-6A6SpPbz_YUI4ElMo-UhuQHaE8.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename  animal_type\n",
       "905  OIP-5ual0F5ZPZRdkGcj8uSH0AHaFj.jpeg            4\n",
       "906  OIP-5VwIBS0B8SxZbUiAHBJg7gHaE8.jpeg            3\n",
       "907  OIP-5WG0rHWAZYtu0utoZfuaAgHaFj.jpeg            3\n",
       "908  OIP-5ZwfeYunG6CT2wEI7OjybQHaEo.jpeg            4\n",
       "909  OIP-6A6SpPbz_YUI4ElMo-UhuQHaE8.jpeg            4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = pd.read_csv(\"submission_01.csv\")\n",
    "check.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3g3ttCgke7i"
   },
   "source": [
    "# **OR,**\n",
    "**If you are working on Google Colab then use the below set of code to save prediction results locally**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-tXRapAkpoe"
   },
   "source": [
    "# **How to save prediction results locally via colab notebook?**\n",
    "If you are working on Google Colab Notebook, execute below block of codes. A file named ‘submission’ will be downloaded in your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGmEaU75kmfq"
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'filename': test_data['filename'], 'animal_type': prediction})  # prediction is nothing but the final predictions of your model on input features of your new unseen test data\n",
    "res.to_csv(\"submission_01.csv\") \n",
    "\n",
    "# To download the csv file locally\n",
    "from google.colab import files        \n",
    "files.download('submission_01.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Getting_Started_Notebook_Intermediate_Assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
